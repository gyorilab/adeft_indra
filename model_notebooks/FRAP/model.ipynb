{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from indra.literature.adeft_tools import universal_extract_text\n",
    "from indra.databases.hgnc_client import get_hgnc_name, get_hgnc_id\n",
    "\n",
    "from adeft.discover import AdeftMiner\n",
    "from adeft.gui import ground_with_gui\n",
    "from adeft.modeling.label import AdeftLabeler\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "from adeft.disambiguate import AdeftDisambiguator\n",
    "\n",
    "\n",
    "from adeft_indra.ground.ground import AdeftGrounder\n",
    "from adeft_indra.model_building.s3 import model_to_s3\n",
    "from adeft_indra.model_building.escape import escape_filename\n",
    "from adeft_indra.db.content import get_pmids_for_agent_text, get_pmids_for_entity, \\\n",
    "    get_plaintexts_for_pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adeft_grounder = AdeftGrounder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortforms = ['FRAP']\n",
    "model_name = ':'.join(sorted(escape_filename(shortform) for shortform in shortforms))\n",
    "results_path = os.path.abspath(os.path.join('../..', 'results', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "miners = dict()\n",
    "all_texts = {}\n",
    "for shortform in shortforms:\n",
    "    pmids = get_pmids_for_agent_text(shortform)\n",
    "    if len(pmids) > 10000:\n",
    "        pmids = random.choices(pmids, k=10000)\n",
    "    text_dict = get_plaintexts_for_pmids(pmids, contains=shortforms)\n",
    "    text_dict = {pmid: text for pmid, text in text_dict.items() if len(text) > 5}\n",
    "    miners[shortform] = AdeftMiner(shortform)\n",
    "    miners[shortform].process_texts(text_dict.values())\n",
    "    all_texts.update(text_dict)\n",
    "\n",
    "longform_dict = {}\n",
    "for shortform in shortforms:\n",
    "    longforms = miners[shortform].get_longforms()\n",
    "    longforms = [(longform, count, score) for longform, count, score in longforms\n",
    "                 if count*score > 1]\n",
    "    longform_dict[shortform] = longforms\n",
    "    \n",
    "combined_longforms = Counter()\n",
    "for longform_rows in longform_dict.values():\n",
    "    combined_longforms.update({longform: count for longform, count, score\n",
    "                               in longform_rows})\n",
    "grounding_map = {}\n",
    "names = {}\n",
    "for longform in combined_longforms:\n",
    "    groundings = adeft_grounder.ground(longform)\n",
    "    if groundings:\n",
    "        grounding = groundings[0]['grounding']\n",
    "        grounding_map[longform] = grounding\n",
    "        names[grounding] = groundings[0]['name']\n",
    "longforms, counts = zip(*combined_longforms.most_common())\n",
    "pos_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fluorescence recovery after photobleaching', 170),\n",
       " ('ferric reducing antioxidant power', 114),\n",
       " ('ferric reducing ability of plasma', 48),\n",
       " ('fluorescence recovery after photo bleaching', 13),\n",
       " ('ferric reducing antioxidant potential', 10),\n",
       " ('fkbp12 rapamycin associated protein', 10),\n",
       " ('ferric ion reducing antioxidant power', 9),\n",
       " ('ferric reducing antioxidant power assay', 6),\n",
       " ('ferric reducing activity in plasma', 5),\n",
       " ('fkbp rapamycin associated protein', 4),\n",
       " ('ferric reduction antioxidant power', 3),\n",
       " ('fkbp 12 rapamycin associated protein', 2),\n",
       " ('antioxidant food', 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(longforms, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2020-10-30 05:19:01] indra.ontology.bio.ontology - Loading INDRA bio ontology from cache at /home/ubuntu/.indra/bio_ontology/1.4/bio_ontology.pkl\n"
     ]
    }
   ],
   "source": [
    "grounding_map, names, pos_labels = ground_with_gui(longforms, counts, \n",
    "                                                   grounding_map=grounding_map,\n",
    "                                                   names=names, pos_labels=pos_labels, no_browser=True, port=8891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [grounding_map, names, pos_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'antioxidant food': 'ungrounded',\n",
       "  'ferric ion reducing antioxidant power': 'ungrounded',\n",
       "  'ferric reducing ability of plasma': 'ungrounded',\n",
       "  'ferric reducing activity in plasma': 'ungrounded',\n",
       "  'ferric reducing antioxidant potential': 'ungrounded',\n",
       "  'ferric reducing antioxidant power': 'ungrounded',\n",
       "  'ferric reducing antioxidant power assay': 'ungrounded',\n",
       "  'ferric reduction antioxidant power': 'ungrounded',\n",
       "  'fkbp 12 rapamycin associated protein': 'ungrounded',\n",
       "  'fkbp rapamycin associated protein': 'HGNC:3942',\n",
       "  'fkbp12 rapamycin associated protein': 'HGNC:3942',\n",
       "  'fluorescence recovery after photo bleaching': 'MESH:D036681',\n",
       "  'fluorescence recovery after photobleaching': 'MESH:D036681'},\n",
       " {'HGNC:3942': 'MTOR',\n",
       "  'MESH:D036681': 'Fluorescence Recovery After Photobleaching'},\n",
       " ['HGNC:3942', 'MESH:D036681']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = [{'antioxidant food': 'ungrounded',\n",
    "  'ferric ion reducing antioxidant power': 'ungrounded',\n",
    "  'ferric reducing ability of plasma': 'ungrounded',\n",
    "  'ferric reducing activity in plasma': 'ungrounded',\n",
    "  'ferric reducing antioxidant potential': 'ungrounded',\n",
    "  'ferric reducing antioxidant power': 'ungrounded',\n",
    "  'ferric reducing antioxidant power assay': 'ungrounded',\n",
    "  'ferric reduction antioxidant power': 'ungrounded',\n",
    "  'fkbp 12 rapamycin associated protein': 'ungrounded',\n",
    "  'fkbp rapamycin associated protein': 'HGNC:3942',\n",
    "  'fkbp12 rapamycin associated protein': 'HGNC:3942',\n",
    "  'fluorescence recovery after photo bleaching': 'MESH:D036681',\n",
    "  'fluorescence recovery after photobleaching': 'MESH:D036681'},\n",
    " {'HGNC:3942': 'MTOR',\n",
    "  'MESH:D036681': 'Fluorescence Recovery After Photobleaching'},\n",
    " ['HGNC:3942', 'MESH:D036681']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_longforms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {shortform: {longform: grounding_map[longform] \n",
    "                              for longform, _, _ in longforms if longform in grounding_map\n",
    "                              and longform not in excluded_longforms}\n",
    "                  for shortform, longforms in longform_dict.items()}\n",
    "result = [grounding_dict, names, pos_labels]\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "with open(os.path.join(results_path, f'{model_name}_preliminary_grounding_info.json'), 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_entities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unambiguous_agent_texts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = AdeftLabeler(grounding_dict)\n",
    "corpus = labeler.build_from_texts((text, pmid) for pmid, text in all_texts.items())\n",
    "agent_text_pmid_map = defaultdict(list)\n",
    "for text, label, id_ in corpus:\n",
    "    agent_text_pmid_map[label].append(id_)\n",
    "\n",
    "entity_pmid_map = {entity: set(get_pmids_for_entity(*entity.split(':', maxsplit=1),\n",
    "                                                major_topic=True))for entity in additional_entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = []\n",
    "for entity1, pmids1 in entity_pmid_map.items():\n",
    "    for entity2, pmids2 in entity_pmid_map.items():\n",
    "        intersection1.append((entity1, entity2, len(pmids1 & pmids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = []\n",
    "for entity1, pmids1 in agent_text_pmid_map.items():\n",
    "    for entity2, pmids2 in entity_pmid_map.items():\n",
    "        intersection2.append((entity1, entity2, len(set(pmids1) & pmids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-659eb348dd4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpmids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_pmids_for_agent_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnew_pmids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmids\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mall_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mused_pmids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtext_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plaintexts_for_pmids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pmids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mused_pmids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_pmids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/adeft/PythonRepos/adeft_indra/adeft_indra/db/content.py\u001b[0m in \u001b[0;36mget_plaintexts_for_pmids\u001b[0;34m(pmids, contains)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Find which pmids have associated plaintexts already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mxmls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_xmls_for_pmids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     plaintexts = {pmid: universal_extract_text(xml, contains=contains)\n\u001b[0m\u001b[1;32m     17\u001b[0m                   for pmid, xml in xmls}\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplaintexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/adeft/PythonRepos/adeft_indra/adeft_indra/db/content.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Find which pmids have associated plaintexts already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mxmls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_xmls_for_pmids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     plaintexts = {pmid: universal_extract_text(xml, contains=contains)\n\u001b[0m\u001b[1;32m     17\u001b[0m                   for pmid, xml in xmls}\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplaintexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/adeft/PythonRepos/indra/indra/literature/adeft_tools.py\u001b[0m in \u001b[0;36muniversal_extract_text\u001b[0;34m(xml, contains)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mParagraphs\u001b[0m \u001b[0mare\u001b[0m \u001b[0mseparated\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniversal_extract_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilter_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/adeft/PythonRepos/indra/indra/literature/adeft_tools.py\u001b[0m in \u001b[0;36muniversal_extract_paragraphs\u001b[0;34m(xml)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melsevier_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/adeft/PythonRepos/indra/indra/literature/elsevier_client.py\u001b[0m in \u001b[0;36mextract_paragraphs\u001b[0;34m(xml_string)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m\"\"\"Get paragraphs from the body of the given Elsevier xml.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mxml_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUTB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxml_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'article:originalText'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melsevier_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_text\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mXML\u001b[0;34m(text, parser)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXMLParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTreeBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_used_pmids = set()\n",
    "for entity, agent_texts in unambiguous_agent_texts.items():\n",
    "    used_pmids = set()\n",
    "    for agent_text in agent_texts:\n",
    "        pmids = set(get_pmids_for_agent_text(agent_text))\n",
    "        new_pmids = list(pmids - all_texts.keys() - used_pmids)\n",
    "        text_dict = get_plaintexts_for_pmids(new_pmids, contains=agent_texts)\n",
    "        corpus.extend([(text, entity, pmid) for pmid, text in text_dict.items()])\n",
    "        used_pmids.update(new_pmids)\n",
    "    all_used_pmids.update(used_pmids)\n",
    "        \n",
    "for entity, pmids in entity_pmid_map.items():\n",
    "    new_pmids = list(set(pmids) - all_texts.keys() - all_used_pmids)\n",
    "    if len(new_pmids) > 10000:\n",
    "        new_pmids = random.choices(new_pmids, k=10000)\n",
    "    text_dict = get_plaintexts_for_pmids(new_pmids, contains=['RTCA', 'RTCD1', 'RPC', 'RTC1', 'RTC'])\n",
    "    corpus.extend([(text, entity, pmid) for pmid, text in text_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.update(additional_entitie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2020-10-30 05:21:55] /adeft/PP/adeft/adeft/modeling/classify.py - Beginning grid search in parameter space:\n",
      "{'C': [100.0], 'max_features': [10000]}\n",
      "INFO: [2020-10-30 05:21:59] /adeft/PP/adeft/adeft/modeling/classify.py - Best f1 score of 0.9648223288588029 found for parameter values:\n",
      "{'logit__C': 100.0, 'tfidf__max_features': 10000}\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "classifier = AdeftClassifier(shortforms, pos_labels=pos_labels, random_state=1729)\n",
    "param_grid = {'C': [100.0], 'max_features': [10000]}\n",
    "texts, labels, pmids = zip(*corpus)\n",
    "classifier.cv(texts, labels, param_grid, cv=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_distribution': {'MESH:D036681': 121,\n",
       "  'HGNC:3942': 11,\n",
       "  'ungrounded': 137},\n",
       " 'f1': {'mean': 0.964822, 'std': 0.008586},\n",
       " 'precision': {'mean': 0.973476, 'std': 0.026447},\n",
       " 'recall': {'mean': 0.962393, 'std': 0.023435},\n",
       " 'ungrounded': {'f1': {'mean': 0.981813, 'std': 0.016273},\n",
       "  'pr': {'mean': 0.985714, 'std': 0.028571},\n",
       "  'rc': {'mean': 0.979064, 'std': 0.027713}},\n",
       " 'HGNC:3942': {'f1': {'mean': 0.853333, 'std': 0.129271},\n",
       "  'pr': {'mean': 0.833333, 'std': 0.210819},\n",
       "  'rc': {'mean': 0.933333, 'std': 0.133333}},\n",
       " 'MESH:D036681': {'f1': {'mean': 0.975326, 'std': 0.007673},\n",
       "  'pr': {'mean': 0.975333, 'std': 0.020149},\n",
       "  'rc': {'mean': 0.976615, 'std': 0.030929}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb.dump(model_name, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for FRAP\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tFluorescence Recovery After Photobleaching*\tMESH:D036681\n",
      "\tMTOR*\tHGNC:3942\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding                                 \tCount\tF1     \n",
      "                                Ungrounded\t137\t0.98181\n",
      "Fluorescence Recovery After Photobleaching*\t121\t0.97533\n",
      "                                      MTOR*\t 11\t0.85333\n",
      "\n",
      "Weighted Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.96482\n",
      "\tPrecision:\t0.97348\n",
      "\tRecall:\t\t0.96239\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disamb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_s3(disamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
