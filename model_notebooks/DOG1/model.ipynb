{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from indra.literature.adeft_tools import universal_extract_text\n",
    "from indra.databases.hgnc_client import get_hgnc_name, get_hgnc_id\n",
    "\n",
    "from adeft.discover import AdeftMiner\n",
    "from adeft.gui import ground_with_gui\n",
    "from adeft.modeling.label import AdeftLabeler\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "from adeft.disambiguate import AdeftDisambiguator, load_disambiguator\n",
    "\n",
    "\n",
    "from adeft_indra.ground.ground import AdeftGrounder\n",
    "from adeft_indra.model_building.s3 import model_to_s3\n",
    "from adeft_indra.model_building.escape import escape_filename\n",
    "from adeft_indra.db.content import get_pmids_for_agent_text, get_pmids_for_entity, \\\n",
    "    get_plaintexts_for_pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adeft_grounder = AdeftGrounder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortforms = ['DOG1']\n",
    "model_name = ':'.join(sorted(escape_filename(shortform) for shortform in shortforms))\n",
    "results_path = os.path.abspath(os.path.join('../..', 'results', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "miners = dict()\n",
    "all_texts = {}\n",
    "for shortform in shortforms:\n",
    "    pmids = get_pmids_for_agent_text(shortform)\n",
    "    text_dict = get_plaintexts_for_pmids(pmids, contains=shortforms)\n",
    "    text_dict = {pmid: text for pmid, text in text_dict.items() if len(text) > 5}\n",
    "    miners[shortform] = AdeftMiner(shortform)\n",
    "    miners[shortform].process_texts(text_dict.values())\n",
    "    all_texts.update(text_dict)\n",
    "\n",
    "longform_dict = {}\n",
    "for shortform in shortforms:\n",
    "    longforms = miners[shortform].get_longforms()\n",
    "    longforms = [(longform, count, score) for longform, count, score in longforms\n",
    "                 if count*score > 2]\n",
    "    longform_dict[shortform] = longforms\n",
    "    \n",
    "combined_longforms = Counter()\n",
    "for longform_rows in longform_dict.values():\n",
    "    combined_longforms.update({longform: count for longform, count, score\n",
    "                               in longform_rows})\n",
    "grounding_map = {}\n",
    "names = {}\n",
    "for longform in combined_longforms:\n",
    "    groundings = adeft_grounder.ground(longform)\n",
    "    if groundings:\n",
    "        grounding = groundings[0]['grounding']\n",
    "        grounding_map[longform] = grounding\n",
    "        names[grounding] = groundings[0]['name']\n",
    "longforms, counts = zip(*combined_longforms.most_common())\n",
    "pos_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('delay of germination 1', 17), ('delay of germination1', 11)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(longforms, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    disamb = load_disambiguator(shortforms[0])\n",
    "    for shortform, gm in disamb.grounding_dict.items():\n",
    "        for longform, grounding in gm.items():\n",
    "            grounding_map[longform] = grounding\n",
    "    for grounding, name in disamb.names.items():\n",
    "        names[grounding] = name\n",
    "    pos_labels = disamb.pos_labels\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UP:A0SVK0': 'Protein DELAY OF GERMINATION 1', 'HGNC:21625': 'ANO1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2020-11-11 05:01:14] indra.ontology.bio.ontology - Loading INDRA bio ontology from cache at /home/ubuntu/.indra/bio_ontology/1.4/bio_ontology.pkl\n"
     ]
    }
   ],
   "source": [
    "grounding_map, names, pos_labels = ground_with_gui(longforms, counts, \n",
    "                                                   grounding_map=grounding_map,\n",
    "                                                   names=names, pos_labels=pos_labels, no_browser=True, port=8891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [grounding_map, names, pos_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'delay of germination 1': 'UP:A0SVK0', 'delay of germination1': 'UP:A0SVK0'},\n",
       " {'UP:A0SVK0': 'Protein DELAY OF GERMINATION 1'},\n",
       " ['UP:A0SVK0']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = [{'delay of germination 1': 'UP:A0SVK0', 'delay of germination1': 'UP:A0SVK0'},\n",
    " {'UP:A0SVK0': 'Protein DELAY OF GERMINATION 1'},\n",
    " ['UP:A0SVK0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_longforms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {shortform: {longform: grounding_map[longform] \n",
    "                              for longform, _, _ in longforms if longform in grounding_map\n",
    "                              and longform not in excluded_longforms}\n",
    "                  for shortform, longforms in longform_dict.items()}\n",
    "result = [grounding_dict, names, pos_labels]\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "with open(os.path.join(results_path, f'{model_name}_preliminary_grounding_info.json'), 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_entities = {'HGNC:21625': ['ANO1', ['DOG1']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unambiguous_agent_texts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = AdeftLabeler(grounding_dict)\n",
    "corpus = labeler.build_from_texts((text, pmid) for pmid, text in all_texts.items())\n",
    "agent_text_pmid_map = defaultdict(list)\n",
    "for text, label, id_ in corpus:\n",
    "    agent_text_pmid_map[label].append(id_)\n",
    "\n",
    "entity_pmid_map = {entity: set(get_pmids_for_entity(*entity.split(':', maxsplit=1),\n",
    "                                                major_topic=True))for entity in additional_entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = []\n",
    "for entity1, pmids1 in entity_pmid_map.items():\n",
    "    for entity2, pmids2 in entity_pmid_map.items():\n",
    "        intersection1.append((entity1, entity2, len(pmids1 & pmids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = []\n",
    "for entity1, pmids1 in agent_text_pmid_map.items():\n",
    "    for entity2, pmids2 in entity_pmid_map.items():\n",
    "        intersection2.append((entity1, entity2, len(set(pmids1) & pmids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HGNC:21625', 'HGNC:21625', 261)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UP:A0SVK0', 'HGNC:21625', 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_pmids = set()\n",
    "for entity, agent_texts in unambiguous_agent_texts.items():\n",
    "    used_pmids = set()\n",
    "    for agent_text in agent_texts[1]:\n",
    "        pmids = set(get_pmids_for_agent_text(agent_text))\n",
    "        new_pmids = list(pmids - all_texts.keys() - used_pmids)\n",
    "        text_dict = get_plaintexts_for_pmids(new_pmids, contains=agent_texts)\n",
    "        corpus.extend([(text, entity, pmid) for pmid, text in text_dict.items() if len(text) >= 5])\n",
    "        used_pmids.update(new_pmids)\n",
    "    all_used_pmids.update(used_pmids)\n",
    "        \n",
    "for entity, pmids in entity_pmid_map.items():\n",
    "    new_pmids = list(set(pmids) - all_texts.keys() - all_used_pmids)\n",
    "    if len(new_pmids) > 10000:\n",
    "        new_pmids = random.choices(new_pmids, k=10000)\n",
    "    _, contains = additional_entities[entity]\n",
    "    text_dict = get_plaintexts_for_pmids(new_pmids, contains=contains)\n",
    "    corpus.extend([(text, entity, pmid) for pmid, text in text_dict.items() if len(text) >= 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.update({key: value[0] for key, value in additional_entities.items()})\n",
    "names.update({key: value[0] for key, value in unambiguous_agent_texts.items()})\n",
    "pos_labels = list(set(pos_labels) | additional_entities.keys() |\n",
    "                  unambiguous_agent_texts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2020-11-11 05:02:43] /adeft/PP/adeft/adeft/modeling/classify.py - Beginning grid search in parameter space:\n",
      "{'C': [100.0], 'max_features': [10000]}\n",
      "INFO: [2020-11-11 05:02:45] /adeft/PP/adeft/adeft/modeling/classify.py - Best f1 score of 1.0 found for parameter values:\n",
      "{'logit__C': 100.0, 'tfidf__max_features': 10000}\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "classifier = AdeftClassifier(shortforms, pos_labels=pos_labels, random_state=1729)\n",
    "param_grid = {'C': [100.0], 'max_features': [10000]}\n",
    "texts, labels, pmids = zip(*corpus)\n",
    "classifier.cv(texts, labels, param_grid, cv=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_distribution': {'UP:A0SVK0': 20, 'HGNC:21625': 60},\n",
       " 'f1': {'mean': 1.0, 'std': 0.0},\n",
       " 'precision': {'mean': 1.0, 'std': 0.0},\n",
       " 'recall': {'mean': 1.0, 'std': 0.0},\n",
       " 'UP:A0SVK0': {'f1': {'mean': 1.0, 'std': 0.0},\n",
       "  'pr': {'mean': 1.0, 'std': 0.0},\n",
       "  'rc': {'mean': 1.0, 'std': 0.0}},\n",
       " 'HGNC:21625': {'f1': {'mean': 1.0, 'std': 0.0},\n",
       "  'pr': {'mean': 1.0, 'std': 0.0},\n",
       "  'rc': {'mean': 1.0, 'std': 0.0}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb.dump(model_name, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for DOG1\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tANO1*\tHGNC:21625\n",
      "\tProtein DELAY OF GERMINATION 1*\tUP:A0SVK0\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding                     \tCount\tF1     \n",
      "                          ANO1*\t60\t    1.0\n",
      "Protein DELAY OF GERMINATION 1*\t20\t    1.0\n",
      "\n",
      "Weighted Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t1.0\n",
      "\tPrecision:\t1.0\n",
      "\tRecall:\t\t1.0\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disamb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_s3(disamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [disamb.disambiguate(text) for text in all_texts.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text for pred, text in zip(preds, all_texts.values()) if pred[0] == 'HGNC:10967']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The non-neuronal monoamine transporters (OCT1, OCT2, EMT, and PMAT) play a key role in the clearance of monoamines from extracellular compartments. In a previous report we described endometrial distribution and cyclic variation of the vesicular monoamine transporter (VMAT2) mRNA and the neuronal norepinephrine transporter (NET) mRNA. In the present study we used in situ hybridization, real-time PCR and immunohistochemistry to reveal tissue distribution and cyclic variation of mRNA for the non-neuronal monoamine transporters in the human endometrium and early pregnancy decidua. We found that non-neuronal monoamine transporters are predominantly expressed in the stroma. The plasma membrane monoamine transporter (PMAT) mRNA expression peaked in the proliferative phase, whereas the extra-neuronal monoamine transporter (EMT) mRNA expression peaked in the secretory phase. The organic cation transporter 2 (OCT2) mRNA expression was exclusively detected in few scattered stromal cells and OCT1 mRNA was not detected at all. Our present results demonstrate that PMAT, EMT, and OCT2 transporters are expressed in the endometrial stroma and can potentially regulate reuptake of monoamines in general and histamine in particular. Taken together with our previous finding of VMAT2 mRNA in epithelial cells, we suggest a paracrine interaction between stromal and epithelial cells, which may modulate certain steps of the reproductive process.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
