{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from indra.literature.adeft_tools import universal_extract_text\n",
    "from indra.databases.hgnc_client import get_hgnc_name, get_hgnc_id\n",
    "\n",
    "from adeft.discover import AdeftMiner\n",
    "from adeft.gui import ground_with_gui\n",
    "from adeft.modeling.label import AdeftLabeler\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "from adeft.disambiguate import AdeftDisambiguator, load_disambiguator\n",
    "\n",
    "\n",
    "from adeft_indra.ground.ground import AdeftGrounder\n",
    "from adeft_indra.model_building.s3 import model_to_s3\n",
    "from adeft_indra.model_building.escape import escape_filename\n",
    "from adeft_indra.db.content import get_pmids_for_agent_text, get_pmids_for_entity, \\\n",
    "    get_plaintexts_for_pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adeft_grounder = AdeftGrounder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortforms = ['CLK']\n",
    "model_name = ':'.join(sorted(escape_filename(shortform) for shortform in shortforms))\n",
    "results_path = os.path.abspath(os.path.join('../..', 'results', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "miners = dict()\n",
    "all_texts = {}\n",
    "for shortform in shortforms:\n",
    "    pmids = get_pmids_for_agent_text(shortform)\n",
    "    if len(pmids) > 10000:\n",
    "        pmids = random.choices(pmids, k=10000)\n",
    "    text_dict = get_plaintexts_for_pmids(pmids, contains=shortforms)\n",
    "    text_dict = {pmid: text for pmid, text in text_dict.items() if len(text) > 5}\n",
    "    miners[shortform] = AdeftMiner(shortform)\n",
    "    miners[shortform].process_texts(text_dict.values())\n",
    "    all_texts.update(text_dict)\n",
    "\n",
    "longform_dict = {}\n",
    "for shortform in shortforms:\n",
    "    longforms = miners[shortform].get_longforms()\n",
    "    longforms = [(longform, count, score) for longform, count, score in longforms\n",
    "                 if count*score > 2]\n",
    "    longform_dict[shortform] = longforms\n",
    "    \n",
    "combined_longforms = Counter()\n",
    "for longform_rows in longform_dict.values():\n",
    "    combined_longforms.update({longform: count for longform, count, score\n",
    "                               in longform_rows})\n",
    "grounding_map = {}\n",
    "names = {}\n",
    "for longform in combined_longforms:\n",
    "    groundings = adeft_grounder.ground(longform)\n",
    "    if groundings:\n",
    "        grounding = groundings[0]['grounding']\n",
    "        grounding_map[longform] = grounding\n",
    "        names[grounding] = groundings[0]['name']\n",
    "longforms, counts = zip(*combined_longforms.most_common())\n",
    "pos_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clock', 110),\n",
       " ('cdc2 like kinase', 7),\n",
       " ('contralateral kidney', 4),\n",
       " ('lin − c kit + progenitor', 4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(longforms, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2020-10-27 04:28:45] indra.ontology.bio.ontology - Loading INDRA bio ontology from cache at /home/ubuntu/.indra/bio_ontology/1.4/bio_ontology.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0cef85b912e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m grounding_map, names, pos_labels = ground_with_gui(longforms, counts, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                    \u001b[0mgrounding_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrounding_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                    names=names, pos_labels=pos_labels, no_browser=True, port=8890)\n",
      "\u001b[0;32m/adeft/PythonRepos/adeft/adeft/gui/__init__.py\u001b[0m in \u001b[0;36mground_with_gui\u001b[0;34m(longforms, scores, grounding_map, names, pos_labels, verbose, port, no_browser, test)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Poll until user submits groundings. Checks if output file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Stop server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mflask_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grounding_map, names, pos_labels = ground_with_gui(longforms, counts, \n",
    "                                                   grounding_map=grounding_map,\n",
    "                                                   names=names, pos_labels=pos_labels, no_browser=True, port=8890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [grounding_map, names, pos_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'benzaldehyde lyase': 'MESH:C059416',\n",
       "  'betaine aldehyde': 'CHEBI:CHEBI:15710',\n",
       "  'bile salt activity lipase': 'HGNC:1848',\n",
       "  'bioartificial liver': 'MESH:D019164',\n",
       "  'blood alcohol levels': 'ungrounded',\n",
       "  'breath alcohol levels': 'ungrounded',\n",
       "  'british anti lewisite': 'CHEBI:CHEBI:64198',\n",
       "  'brochoalveolar lavage': 'MESH:D018893',\n",
       "  'bronchalveolar lavage': 'MESH:D018893',\n",
       "  'bronchial alveolar lavage': 'MESH:D018893',\n",
       "  'bronchial lavage': 'MESH:D018893',\n",
       "  'bronchio alveolar lavage': 'MESH:D018893',\n",
       "  'bronchiolar lavage': 'MESH:D018893',\n",
       "  'broncho alveolar lavage': 'MESH:D018893',\n",
       "  'bronchoalveolar': 'MESH:D018893',\n",
       "  'bronchoalveolar fluid': 'MESH:D018893',\n",
       "  'bronchoalveolar larvage': 'MESH:D018893',\n",
       "  'bronchoalveolar lavage': 'MESH:D018893'},\n",
       " {'MESH:C059416': 'benzaldehyde lyase',\n",
       "  'CHEBI:CHEBI:15710': 'betaine aldehyde',\n",
       "  'HGNC:1848': 'CEL',\n",
       "  'MESH:D019164': 'Liver, Artificial',\n",
       "  'CHEBI:CHEBI:64198': 'dimercaprol',\n",
       "  'MESH:D018893': 'Bronchoalveolar Lavage'},\n",
       " ['HGNC:1848', 'MESH:D018893']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_disambiguator('CLK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [d.grounding_dict['CLK'], d.names, d.pos_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cdc2 like kinase': 'FPLX:CLK',\n",
       "  'clock': 'HGNC:2082',\n",
       "  'contralateral kidney': 'ungrounded'},\n",
       " {'FPLX:CLK': 'CLK', 'HGNC:2082': 'CLOCK'},\n",
       " ['FPLX:CLK', 'HGNC:2082']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = [{'cdc2 like kinase': 'FPLX:CLK',\n",
    "  'clock': 'HGNC:2082',\n",
    "  'contralateral kidney': 'ungrounded',\n",
    "  'lin − c kit + progenitor': 'ungrounded'},\n",
    " {'FPLX:CLK': 'CLK', 'HGNC:2082': 'CLOCK'},\n",
    " ['FPLX:CLK', 'HGNC:2082']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_longforms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {shortform: {longform: grounding_map[longform] \n",
    "                              for longform, _, _ in longforms if longform in grounding_map\n",
    "                              and longform not in excluded_longforms}\n",
    "                  for shortform, longforms in longform_dict.items()}\n",
    "result = [grounding_dict, names, pos_labels]\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "with open(os.path.join(results_path, f'{model_name}_preliminary_grounding_info.json'), 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_entities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unambiguous_agent_texts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = AdeftLabeler(grounding_dict)\n",
    "corpus = labeler.build_from_texts((text, pmid) for pmid, text in all_texts.items())\n",
    "agent_text_pmid_map = defaultdict(list)\n",
    "for text, label, id_ in corpus:\n",
    "    agent_text_pmid_map[label].append(id_)\n",
    "\n",
    "entity_pmid_map = {entity: set(get_pmids_for_entity(*entity.split(':', maxsplit=1),\n",
    "                                                major_topic=True))for entity in additional_entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = []\n",
    "for entity1, pmids1 in entity_pmid_map.items():\n",
    "    for entity2, pmids2 in entity_pmid_map.items():\n",
    "        intersection1.append((entity1, entity2, len(pmids1 & pmids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = []\n",
    "for entity1, pmids1 in agent_text_pmid_map.items():\n",
    "    for entity2, pmids2 in entity_pmid_map.items():\n",
    "        intersection2.append((entity1, entity2, len(set(pmids1) & pmids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FPLX:CLK', 'FPLX:CLK', 0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MESH:D018893', 'HGNC:1848', 0),\n",
       " ('HGNC:1848', 'HGNC:1848', 1),\n",
       " ('ungrounded', 'HGNC:1848', 0),\n",
       " ('CHEBI:CHEBI:64198', 'HGNC:1848', 0),\n",
       " ('MESH:D019164', 'HGNC:1848', 0),\n",
       " ('MESH:C059416', 'HGNC:1848', 0),\n",
       " ('CHEBI:CHEBI:15710', 'HGNC:1848', 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_pmids = set()\n",
    "for entity, agent_texts in unambiguous_agent_texts.items():\n",
    "    used_pmids = set()\n",
    "    for agent_text in agent_texts:\n",
    "        pmids = set(get_pmids_for_agent_text(agent_text))\n",
    "        new_pmids = list(pmids - all_texts.keys() - used_pmids)\n",
    "        text_dict = get_plaintexts_for_pmids(new_pmids, contains=agent_texts)\n",
    "        corpus.extend([(text, entity, pmid) for pmid, text in text_dict.items()])\n",
    "        used_pmids.update(new_pmids)\n",
    "    all_used_pmids.update(used_pmids)\n",
    "        \n",
    "for entity, pmids in entity_pmid_map.items():\n",
    "    new_pmids = list(set(pmids) - all_texts.keys() - all_used_pmids)\n",
    "    if len(new_pmids) > 10000:\n",
    "        new_pmids = random.choices(new_pmids, k=10000)\n",
    "    _, contains = additional_entities[entity]\n",
    "    text_dict = get_plaintexts_for_pmids(new_pmids, contains=contains)\n",
    "    corpus.extend([(text, entity, pmid) for pmid, text in text_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.update({key: value[0] for key, value in additional_entities.values()})\n",
    "pos_labels = list(set(pos_labels) | additional_entities.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2020-10-27 04:33:09] /adeft/PythonRepos/adeft/adeft/modeling/classify.py - Beginning grid search in parameter space:\n",
      "{'C': [100.0], 'max_features': [10000]}\n",
      "INFO: [2020-10-27 04:33:12] /adeft/PythonRepos/adeft/adeft/modeling/classify.py - Best f1 score of 0.9388971848902162 found for parameter values:\n",
      "{'logit__C': 100.0, 'tfidf__max_features': 10000}\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "classifier = AdeftClassifier(shortforms, pos_labels=pos_labels, random_state=1729)\n",
    "param_grid = {'C': [100.0], 'max_features': [10000]}\n",
    "texts, labels, pmids = zip(*corpus)\n",
    "classifier.cv(texts, labels, param_grid, cv=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_distribution': {'ungrounded': 5, 'HGNC:2082': 100, 'FPLX:CLK': 5},\n",
       " 'f1': {'mean': 0.938897, 'std': 0.03173},\n",
       " 'precision': {'mean': 0.917378, 'std': 0.04429},\n",
       " 'recall': {'mean': 0.961905, 'std': 0.019048},\n",
       " 'ungrounded': {'f1': {'mean': 0.8, 'std': 0.4},\n",
       "  'pr': {'mean': 0.8, 'std': 0.4},\n",
       "  'rc': {'mean': 0.8, 'std': 0.4}},\n",
       " 'HGNC:2082': {'f1': {'mean': 0.975842, 'std': 0.015061},\n",
       "  'pr': {'mean': 1.0, 'std': 0.0},\n",
       "  'rc': {'mean': 0.953247, 'std': 0.028768}},\n",
       " 'FPLX:CLK': {'f1': {'mean': 0.2, 'std': 0.4},\n",
       "  'pr': {'mean': 0.2, 'std': 0.4},\n",
       "  'rc': {'mean': 0.2, 'std': 0.4}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb.dump(model_name, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for CLK\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tCLK*\tFPLX:CLK\n",
      "\tCLOCK*\tHGNC:2082\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding\tCount\tF1     \n",
      "CLOCK*\t100\t0.97584\n",
      "Ungrounded\t  5\t    0.8\n",
      "  CLK*\t  5\t    0.2\n",
      "\n",
      "Weighted Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.9389\n",
      "\tPrecision:\t0.91738\n",
      "\tRecall:\t\t0.9619\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disamb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_s3(disamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
