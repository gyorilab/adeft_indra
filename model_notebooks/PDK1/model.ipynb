{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from indra.literature.adeft_tools import universal_extract_text\n",
    "from indra.databases.hgnc_client import get_hgnc_name, get_hgnc_id\n",
    "\n",
    "from adeft.discover import AdeftMiner\n",
    "from adeft.gui import ground_with_gui\n",
    "from adeft.modeling.label import AdeftLabeler\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "from adeft.disambiguate import AdeftDisambiguator, load_disambiguator\n",
    "\n",
    "from indra_db_lite.api import get_entrez_pmids_for_hgnc\n",
    "from indra_db_lite.api import get_entrez_pmids_for_uniprot\n",
    "from indra_db_lite.api import get_plaintexts_for_text_ref_ids\n",
    "from indra_db_lite.api import get_text_ref_ids_for_agent_text\n",
    "from indra_db_lite.api import get_text_ref_ids_for_pmids\n",
    "\n",
    "\n",
    "from adeft_indra.grounding import AdeftGrounder\n",
    "from adeft_indra.s3 import model_to_s3\n",
    "from adeft_indra.model_building.escape import escape_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_ref_ids_for_entity(ns, id_):\n",
    "    if ns == 'HGNC':\n",
    "        pmids = get_entrez_pmids_for_hgnc(id_)\n",
    "    elif ns == 'UP':\n",
    "        pmids = get_entrez_pmids_for_uniprot(id_)\n",
    "    return list(get_text_ref_ids_for_pmids(pmids).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adeft_grounder = AdeftGrounder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortforms = ['PDK1']\n",
    "model_name = '&'.join(sorted(escape_filename(shortform) for shortform in shortforms))\n",
    "results_path = os.path.abspath(os.path.join('../../', 'results', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "miners = dict()\n",
    "all_texts = {}\n",
    "for shortform in shortforms:\n",
    "    text_ref_ids = get_text_ref_ids_for_agent_text(shortform)\n",
    "    content = get_plaintexts_for_text_ref_ids(text_ref_ids, contains=shortforms)\n",
    "    text_dict = content.flatten()\n",
    "    miners[shortform] = AdeftMiner(shortform)\n",
    "    miners[shortform].process_texts(text_dict.values())\n",
    "    all_texts.update(text_dict)\n",
    "\n",
    "longform_dict = {}\n",
    "for shortform in shortforms:\n",
    "    longforms = miners[shortform].get_longforms()\n",
    "    longforms = [(longform, count, score) for longform, count, score in longforms\n",
    "                 if count*score > 2]\n",
    "    longform_dict[shortform] = longforms\n",
    "    \n",
    "combined_longforms = Counter()\n",
    "for longform_rows in longform_dict.values():\n",
    "    combined_longforms.update({longform: count for longform, count, score\n",
    "                               in longform_rows})\n",
    "grounding_map = {}\n",
    "names = {}\n",
    "for longform in combined_longforms:\n",
    "    groundings = adeft_grounder.ground(longform)\n",
    "    if groundings:\n",
    "        grounding = groundings[0]['grounding']\n",
    "        grounding_map[longform] = grounding\n",
    "        names[grounding] = groundings[0]['name']\n",
    "longforms, counts = zip(*combined_longforms.most_common())\n",
    "pos_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phosphoinositide dependent kinase 1', 491),\n",
       " ('phosphoinositide dependent kinase', 22),\n",
       " ('dependent protein kinase', 17),\n",
       " ('pdk1', 9),\n",
       " ('pdk1 wild type', 8),\n",
       " ('pyruvate dehydrogenase kinase isozyme 1', 7),\n",
       " ('phosphoinositide dependent kinase l', 7),\n",
       " ('pyruvate dehydrogenase kinase isoenzyme 1', 5),\n",
       " ('pdpk1', 3),\n",
       " ('dependent protein kinase1', 3),\n",
       " ('pyruvate dehydrogenase lipoamide kinase isozyme 1', 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(longforms, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = ground_with_gui(longforms, counts, \n",
    "                                                   grounding_map=grounding_map,\n",
    "                                                   names=names, pos_labels=pos_labels, no_browser=True, port=8890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [grounding_map, names, pos_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dependent protein kinase': 'HGNC:8816',\n",
       "  'dependent protein kinase1': 'HGNC:8816',\n",
       "  'pdk1': 'ungrounded',\n",
       "  'pdk1 wild type': 'ungrounded',\n",
       "  'pdpk1': 'HGNC:8816',\n",
       "  'phosphoinositide dependent kinase': 'HGNC:8816',\n",
       "  'phosphoinositide dependent kinase 1': 'HGNC:8816',\n",
       "  'phosphoinositide dependent kinase l': 'HGNC:8816',\n",
       "  'pyruvate dehydrogenase kinase isoenzyme 1': 'HGNC:8809',\n",
       "  'pyruvate dehydrogenase kinase isozyme 1': 'HGNC:8809',\n",
       "  'pyruvate dehydrogenase lipoamide kinase isozyme 1': 'HGNC:8809'},\n",
       " {'HGNC:8816': 'PDPK1', 'HGNC:8809': 'PDK1'},\n",
       " ['HGNC:8809', 'HGNC:8816']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = [{'dependent protein kinase': 'HGNC:8816',\n",
    "  'dependent protein kinase1': 'HGNC:8816',\n",
    "  'pdk1': 'ungrounded',\n",
    "  'pdk1 wild type': 'ungrounded',\n",
    "  'pdpk1': 'HGNC:8816',\n",
    "  'phosphoinositide dependent kinase': 'HGNC:8816',\n",
    "  'phosphoinositide dependent kinase 1': 'HGNC:8816',\n",
    "  'phosphoinositide dependent kinase l': 'HGNC:8816',\n",
    "  'pyruvate dehydrogenase kinase isoenzyme 1': 'HGNC:8809',\n",
    "  'pyruvate dehydrogenase kinase isozyme 1': 'HGNC:8809',\n",
    "  'pyruvate dehydrogenase lipoamide kinase isozyme 1': 'HGNC:8809'},\n",
    " {'HGNC:8816': 'PDPK1', 'HGNC:8809': 'PDK1'},\n",
    " ['HGNC:8809', 'HGNC:8816']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_longforms = ['pdk1', 'pdk1 wild type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {shortform: {longform: grounding_map[longform] \n",
    "                              for longform, _, _ in longforms if longform in grounding_map\n",
    "                              and longform not in excluded_longforms}\n",
    "                  for shortform, longforms in longform_dict.items()}\n",
    "result = [grounding_dict, names, pos_labels]\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "with open(os.path.join(results_path, f'{model_name}_preliminary_grounding_info.json'), 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_entities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "unambiguous_agent_texts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = AdeftLabeler(grounding_dict)\n",
    "corpus = labeler.build_from_texts(\n",
    "    (text, text_ref_id) for text_ref_id, text in all_texts.items()\n",
    ")\n",
    "agent_text_text_ref_id_map = defaultdict(list)\n",
    "for text, label, id_ in corpus:\n",
    "    agent_text_text_ref_id_map[label].append(id_)\n",
    "\n",
    "entity_text_ref_id_map = {\n",
    "    entity: set(\n",
    "        get_text_ref_ids_for_entity(*entity.split(':', maxsplit=1))\n",
    "    )\n",
    "    for entity in additional_entities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = []\n",
    "for entity1, trids1 in entity_text_ref_id_map.items():\n",
    "    for entity2, trids2 in entity_text_ref_id_map.items():\n",
    "        intersection1.append((entity1, entity2, len(trids1 & trids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = []\n",
    "for entity1, trids1 in agent_text_text_ref_id_map.items():\n",
    "    for entity2, pmids2 in entity_text_ref_id_map.items():\n",
    "        intersection2.append((entity1, entity2, len(set(trids1) & trids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_trids = set()\n",
    "for entity, agent_texts in unambiguous_agent_texts.items():\n",
    "    used_trids = set()\n",
    "    for agent_text in agent_texts[1]:\n",
    "        trids = set(get_text_ref_ids_for_agent_text(agent_text))\n",
    "        new_trids = list(trids - all_texts.keys() - used_trids)\n",
    "        content = get_plaintexts_for_text_ref_ids(new_trids, contains=agent_texts[1])\n",
    "        text_dict = content.flatten()\n",
    "        corpus.extend(\n",
    "            [\n",
    "                (text, entity, trid) for trid, text in text_dict.items() if len(text) >= 5\n",
    "            ]\n",
    "        )\n",
    "        used_trids.update(new_trids)\n",
    "    all_used_trids.update(used_trids)\n",
    "        \n",
    "for entity, trids in entity_text_ref_id_map.items():\n",
    "    new_trids = list(set(trids) - all_texts.keys() - all_used_trids)\n",
    "    _, contains = additional_entities[entity]\n",
    "    content = get_plaintexts_for_text_ref_ids(new_trids, contains=contains)\n",
    "    text_dict = content.flatten()\n",
    "    corpus.extend(\n",
    "        [\n",
    "            (text, entity, trid) for trid, text in text_dict.items() if len(text) >= 5\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.update({key: value[0] for key, value in additional_entities.items()})\n",
    "names.update({key: value[0] for key, value in unambiguous_agent_texts.items()})\n",
    "pos_labels = list(set(pos_labels) | additional_entities.keys() |\n",
    "                  unambiguous_agent_texts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2021-10-09 16:20:41] /adeft/Py/adeft/adeft/modeling/classify.py - Beginning grid search in parameter space:\n",
      "{'C': [100.0], 'max_features': [10000]}\n",
      "INFO: [2021-10-09 16:20:44] /adeft/Py/adeft/adeft/modeling/classify.py - Best f1 score of 0.980079207920792 found for parameter values:\n",
      "{'logit__C': 100.0, 'tfidf__max_features': 10000}\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "classifier = AdeftClassifier(shortforms, pos_labels=pos_labels, random_state=1729)\n",
    "param_grid = {'C': [100.0], 'max_features': [10000]}\n",
    "texts, labels, pmids = zip(*corpus)\n",
    "classifier.cv(texts, labels, param_grid, cv=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_distribution': {'HGNC:8816': 488, 'HGNC:8809': 14},\n",
       " 'f1': {'mean': 0.980079, 'std': 0.006325},\n",
       " 'precision': {'mean': 0.980079, 'std': 0.006325},\n",
       " 'recall': {'mean': 0.980079, 'std': 0.006325},\n",
       " 'HGNC:8809': {'f1': {'mean': 0.546667, 'std': 0.104563},\n",
       "  'pr': {'mean': 0.433333, 'std': 0.133333},\n",
       "  'rc': {'mean': 0.833333, 'std': 0.210819}},\n",
       " 'HGNC:8816': {'f1': {'mean': 0.989806, 'std': 0.003261},\n",
       "  'pr': {'mean': 0.995876, 'std': 0.00505},\n",
       "  'rc': {'mean': 0.983836, 'std': 0.004868}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb.dump(model_name, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for PDK1\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tPDK1*\tHGNC:8809\n",
      "\tPDPK1*\tHGNC:8816\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding\tCount\tF1     \n",
      "PDPK1*\t488\t0.98981\n",
      " PDK1*\t 14\t0.54667\n",
      "\n",
      "Global Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.98008\n",
      "\tPrecision:\t0.98008\n",
      "\tRecall:\t\t0.98008\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disamb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_s3(disamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adeft.disambiguate import load_disambiguator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = load_disambiguator(\"BAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<adeft.disambiguate.AdeftDisambiguator at 0x7f4f001b33a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for BAL\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tBronchoalveolar Lavage\tMESH:D018893\n",
      "\tCEL*\tHGNC:1848\n",
      "\tLiver, Artificial\tMESH:D019164\n",
      "\tbenzaldehyde lyase*\tMESH:C059416\n",
      "\tbetaine aldehyde*\tCHEBI:CHEBI:15710\n",
      "\tdimercaprol*\tCHEBI:CHEBI:64198\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding             \tCount\tF1     \n",
      "Bronchoalveolar Lavage\t1259\t 0.9929\n",
      "                   CEL*\t  36\t    1.0\n",
      "     Liver, Artificial\t  18\t0.83619\n",
      "            Ungrounded\t  17\t   0.65\n",
      "           dimercaprol*\t   8\t    0.4\n",
      "    benzaldehyde lyase*\t   3\t    0.2\n",
      "      betaine aldehyde*\t   2\t    0.2\n",
      "\n",
      "Global Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.90773\n",
      "\tPrecision:\t1.0\n",
      "\tRecall:\t\t0.83293\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(_28.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
