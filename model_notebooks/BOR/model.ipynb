{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from indra.literature.adeft_tools import universal_extract_text\n",
    "from indra.databases.hgnc_client import get_hgnc_name, get_hgnc_id\n",
    "\n",
    "from adeft.discover import AdeftMiner\n",
    "from adeft.gui import ground_with_gui\n",
    "from adeft.modeling.label import AdeftLabeler\n",
    "from adeft.modeling.classify import AdeftClassifier\n",
    "from adeft.disambiguate import AdeftDisambiguator, load_disambiguator\n",
    "\n",
    "from indra_db_lite.api import get_entrez_pmids_for_hgnc\n",
    "from indra_db_lite.api import get_entrez_pmids_for_uniprot\n",
    "from indra_db_lite.api import get_plaintexts_for_text_ref_ids\n",
    "from indra_db_lite.api import get_text_ref_ids_for_agent_text\n",
    "from indra_db_lite.api import get_text_ref_ids_for_pmids\n",
    "\n",
    "\n",
    "from adeft_indra.grounding import AdeftGrounder\n",
    "from adeft_indra.s3 import model_to_s3\n",
    "from adeft_indra.model_building.escape import escape_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_ref_ids_for_entity(ns, id_):\n",
    "    if ns == 'HGNC':\n",
    "        pmids = get_entrez_pmids_for_hgnc(id_)\n",
    "    elif ns == 'UP':\n",
    "        pmids = get_entrez_pmids_for_uniprot(id_)\n",
    "    return list(get_text_ref_ids_for_pmids(pmids).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adeft_grounder = AdeftGrounder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortforms = ['BOR']\n",
    "model_name = ':'.join(sorted(escape_filename(shortform) for shortform in shortforms))\n",
    "results_path = os.path.abspath(os.path.join('../../', 'results', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "miners = dict()\n",
    "all_texts = {}\n",
    "for shortform in shortforms:\n",
    "    text_ref_ids = get_text_ref_ids_for_agent_text(shortform)\n",
    "    content = get_plaintexts_for_text_ref_ids(text_ref_ids, contains=shortforms)\n",
    "    text_dict = content.flatten()\n",
    "    miners[shortform] = AdeftMiner(shortform)\n",
    "    miners[shortform].process_texts(text_dict.values())\n",
    "    all_texts.update(text_dict)\n",
    "\n",
    "longform_dict = {}\n",
    "for shortform in shortforms:\n",
    "    longforms = miners[shortform].get_longforms()\n",
    "    longforms = [(longform, count, score) for longform, count, score in longforms\n",
    "                 if count*score > 2]\n",
    "    longform_dict[shortform] = longforms\n",
    "    \n",
    "combined_longforms = Counter()\n",
    "for longform_rows in longform_dict.values():\n",
    "    combined_longforms.update({longform: count for longform, count, score\n",
    "                               in longform_rows})\n",
    "grounding_map = {}\n",
    "names = {}\n",
    "for longform in combined_longforms:\n",
    "    groundings = adeft_grounder.ground(longform)\n",
    "    if groundings:\n",
    "        grounding = groundings[0]['grounding']\n",
    "        grounding_map[longform] = grounding\n",
    "        names[grounding] = groundings[0]['name']\n",
    "longforms, counts = zip(*combined_longforms.most_common())\n",
    "pos_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('branchio oto renal', 15),\n",
       " ('bortezomib', 13),\n",
       " ('best overall response', 7),\n",
       " ('bed occupancy rate', 3),\n",
       " ('branchio oto renal syndrome', 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(longforms, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = ground_with_gui(longforms, counts, \n",
    "                                                   grounding_map=grounding_map,\n",
    "                                                   names=names, pos_labels=pos_labels, no_browser=True, port=8890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [grounding_map, names, pos_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bed occupancy rate': 'ungrounded',\n",
       "  'best overall response': 'ungrounded',\n",
       "  'bortezomib': 'CHEBI:CHEBI:52717',\n",
       "  'branchio oto renal': 'MESH:D019280',\n",
       "  'branchio oto renal syndrome': 'MESH:D019280'},\n",
       " {'CHEBI:CHEBI:52717': 'bortezomib',\n",
       "  'MESH:D019280': 'Branchio-Oto-Renal Syndrome'},\n",
       " ['CHEBI:CHEBI:52717', 'MESH:D019280']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_map, names, pos_labels = [{'bed occupancy rate': 'ungrounded',\n",
    "  'best overall response': 'ungrounded',\n",
    "  'bortezomib': 'CHEBI:CHEBI:52717',\n",
    "  'branchio oto renal': 'MESH:D019280',\n",
    "  'branchio oto renal syndrome': 'MESH:D019280'},\n",
    " {'CHEBI:CHEBI:52717': 'bortezomib',\n",
    "  'MESH:D019280': 'Branchio-Oto-Renal Syndrome'},\n",
    " ['CHEBI:CHEBI:52717']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_longforms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_dict = {shortform: {longform: grounding_map[longform] \n",
    "                              for longform, _, _ in longforms if longform in grounding_map\n",
    "                              and longform not in excluded_longforms}\n",
    "                  for shortform, longforms in longform_dict.items()}\n",
    "result = [grounding_dict, names, pos_labels]\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "with open(os.path.join(results_path, f'{model_name}_preliminary_grounding_info.json'), 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_entities = {\n",
    "    'HGNC:14629': ['CDCA8', ['BOR', 'borealin', 'Borealin']],\n",
    "    'HGNC:3519': ['EYA1', ['BOR']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "unambiguous_agent_texts = {'HGNC:14629': ['CDCA8', ['borealin', 'Borealin']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = AdeftLabeler(grounding_dict)\n",
    "corpus = labeler.build_from_texts(\n",
    "    (text, text_ref_id) for text_ref_id, text in all_texts.items()\n",
    ")\n",
    "agent_text_text_ref_id_map = defaultdict(list)\n",
    "for text, label, id_ in corpus:\n",
    "    agent_text_text_ref_id_map[label].append(id_)\n",
    "\n",
    "entity_text_ref_id_map = {\n",
    "    entity: set(\n",
    "        get_text_ref_ids_for_entity(*entity.split(':', maxsplit=1))\n",
    "    )\n",
    "    for entity in additional_entities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection1 = []\n",
    "for entity1, trids1 in entity_text_ref_id_map.items():\n",
    "    for entity2, trids2 in entity_text_ref_id_map.items():\n",
    "        intersection1.append((entity1, entity2, len(trids1 & trids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection2 = []\n",
    "for entity1, trids1 in agent_text_text_ref_id_map.items():\n",
    "    for entity2, pmids2 in entity_text_ref_id_map.items():\n",
    "        intersection2.append((entity1, entity2, len(set(trids1) & trids2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HGNC:14629', 'HGNC:14629', 81),\n",
       " ('HGNC:14629', 'HGNC:3519', 7),\n",
       " ('HGNC:3519', 'HGNC:14629', 7),\n",
       " ('HGNC:3519', 'HGNC:3519', 94)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CHEBI:CHEBI:52717', 'HGNC:14629', 0),\n",
       " ('CHEBI:CHEBI:52717', 'HGNC:3519', 0),\n",
       " ('ungrounded', 'HGNC:14629', 0),\n",
       " ('ungrounded', 'HGNC:3519', 0),\n",
       " ('MESH:D019280', 'HGNC:14629', 5),\n",
       " ('MESH:D019280', 'HGNC:3519', 5)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_trids = set()\n",
    "for entity, agent_texts in unambiguous_agent_texts.items():\n",
    "    used_trids = set()\n",
    "    for agent_text in agent_texts[1]:\n",
    "        trids = set(get_text_ref_ids_for_agent_text(agent_text))\n",
    "        new_trids = list(trids - all_texts.keys() - used_trids)\n",
    "        content = get_plaintexts_for_text_ref_ids(new_trids, contains=agent_texts[1])\n",
    "        text_dict = content.flatten()\n",
    "        corpus.extend(\n",
    "            [\n",
    "                (text, entity, trid) for trid, text in text_dict.items() if len(text) >= 5\n",
    "            ]\n",
    "        )\n",
    "        used_trids.update(new_trids)\n",
    "    all_used_trids.update(used_trids)\n",
    "        \n",
    "for entity, trids in entity_text_ref_id_map.items():\n",
    "    new_trids = list(set(trids) - all_texts.keys() - all_used_trids)\n",
    "    _, contains = additional_entities[entity]\n",
    "    content = get_plaintexts_for_text_ref_ids(new_trids, contains=contains)\n",
    "    text_dict = content.flatten()\n",
    "    corpus.extend(\n",
    "        [\n",
    "            (text, entity, trid) for trid, text in text_dict.items() if len(text) >= 5\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.update({key: value[0] for key, value in additional_entities.items()})\n",
    "names.update({key: value[0] for key, value in unambiguous_agent_texts.items()})\n",
    "pos_labels = list(set(pos_labels) | additional_entities.keys() |\n",
    "                  unambiguous_agent_texts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [2021-10-05 16:20:23] /adeft/Py/adeft/adeft/modeling/classify.py - Beginning grid search in parameter space:\n",
      "{'C': [100.0], 'max_features': [10000]}\n",
      "INFO: [2021-10-05 16:20:25] /adeft/Py/adeft/adeft/modeling/classify.py - Best f1 score of 0.94789764088898 found for parameter values:\n",
      "{'logit__C': 100.0, 'tfidf__max_features': 10000}\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "classifier = AdeftClassifier(shortforms, pos_labels=pos_labels, random_state=1729)\n",
    "param_grid = {'C': [100.0], 'max_features': [10000]}\n",
    "texts, labels, pmids = zip(*corpus)\n",
    "classifier.cv(texts, labels, param_grid, cv=5, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_distribution': {'CHEBI:CHEBI:52717': 11,\n",
       "  'ungrounded': 7,\n",
       "  'MESH:D019280': 11,\n",
       "  'HGNC:14629': 143,\n",
       "  'HGNC:3519': 35},\n",
       " 'f1': {'mean': 0.947898, 'std': 0.019148},\n",
       " 'precision': {'mean': 0.928698, 'std': 0.019784},\n",
       " 'recall': {'mean': 0.967987, 'std': 0.020345},\n",
       " 'CHEBI:CHEBI:52717': {'f1': {'mean': 0.626667, 'std': 0.336254},\n",
       "  'pr': {'mean': 0.533333, 'std': 0.323179},\n",
       "  'rc': {'mean': 0.8, 'std': 0.4}},\n",
       " 'HGNC:14629': {'f1': {'mean': 0.982815, 'std': 0.010907},\n",
       "  'pr': {'mean': 1.0, 'std': 0.0},\n",
       "  'rc': {'mean': 0.966437, 'std': 0.021087}},\n",
       " 'HGNC:3519': {'f1': {'mean': 0.871667, 'std': 0.042361},\n",
       "  'pr': {'mean': 0.971429, 'std': 0.057143},\n",
       "  'rc': {'mean': 0.791667, 'std': 0.043033}},\n",
       " 'MESH:D019280': {'f1': {'mean': 0.213333, 'std': 0.27455},\n",
       "  'pr': {'mean': 0.166667, 'std': 0.210819},\n",
       "  'rc': {'mean': 0.3, 'std': 0.4}},\n",
       " 'ungrounded': {'f1': {'mean': 1.0, 'std': 0.0},\n",
       "  'pr': {'mean': 1.0, 'std': 0.0},\n",
       "  'rc': {'mean': 1.0, 'std': 0.0}}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = AdeftDisambiguator(classifier, grounding_dict, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb.dump(model_name, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for BOR\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tBranchio-Oto-Renal Syndrome\tMESH:D019280\n",
      "\tCDCA8*\tHGNC:14629\n",
      "\tEYA1*\tHGNC:3519\n",
      "\tbortezomib*\tCHEBI:CHEBI:52717\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding                  \tCount\tF1     \n",
      "                      CDCA8*\t143\t0.98282\n",
      "                       EYA1*\t 35\t0.87167\n",
      "                 bortezomib*\t 11\t0.62667\n",
      "Branchio-Oto-Renal Syndrome\t 11\t0.21333\n",
      "                 Ungrounded\t  7\t    1.0\n",
      "\n",
      "Global Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.9479\n",
      "\tPrecision:\t0.9287\n",
      "\tRecall:\t\t0.96799\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disamb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_s3(disamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for BOR\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tBranchio-Oto-Renal Syndrome\tMESH:D019280\n",
      "\tCDCA8*\tHGNC:14629\n",
      "\tEYA1*\tHGNC:3519\n",
      "\tbortezomib*\tCHEBI:CHEBI:52717\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding                  \tCount\tF1     \n",
      "                      CDCA8*\t143\t0.98282\n",
      "                       EYA1*\t 35\t0.87167\n",
      "                 bortezomib*\t 11\t0.62667\n",
      "Branchio-Oto-Renal Syndrome\t 11\t0.21333\n",
      "                 Ungrounded\t  7\t    1.0\n",
      "\n",
      "Global Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.9479\n",
      "\tPrecision:\t0.9287\n",
      "\tRecall:\t\t0.96799\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(disamb.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "disamb = load_disambiguator(\"BAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<adeft.disambiguate.AdeftDisambiguator at 0x7f4f001b33a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disambiguation model for BAL\n",
      "\n",
      "Produces the disambiguations:\n",
      "\tBronchoalveolar Lavage\tMESH:D018893\n",
      "\tCEL*\tHGNC:1848\n",
      "\tLiver, Artificial\tMESH:D019164\n",
      "\tbenzaldehyde lyase*\tMESH:C059416\n",
      "\tbetaine aldehyde*\tCHEBI:CHEBI:15710\n",
      "\tdimercaprol*\tCHEBI:CHEBI:64198\n",
      "\n",
      "Class level metrics:\n",
      "--------------------\n",
      "Grounding             \tCount\tF1     \n",
      "Bronchoalveolar Lavage\t1259\t 0.9929\n",
      "                   CEL*\t  36\t    1.0\n",
      "     Liver, Artificial\t  18\t0.83619\n",
      "            Ungrounded\t  17\t   0.65\n",
      "           dimercaprol*\t   8\t    0.4\n",
      "    benzaldehyde lyase*\t   3\t    0.2\n",
      "      betaine aldehyde*\t   2\t    0.2\n",
      "\n",
      "Global Metrics:\n",
      "-----------------\n",
      "\tF1 score:\t0.90773\n",
      "\tPrecision:\t1.0\n",
      "\tRecall:\t\t0.83293\n",
      "\n",
      "* Positive labels\n",
      "See Docstring for explanation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/adeft/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(_28.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
